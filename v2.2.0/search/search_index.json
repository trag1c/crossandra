{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Crossandra","text":"<p>Crossandra is a fast and simple tokenization library for Python operating on enums and regular expressions, with a decent amount of configuration.</p>"},{"location":"#installation","title":"Installation","text":"<p>Crossandra is available on PyPI and can be installed with pip, or any other Python package manager: <pre><code>$ pip install crossandra\n</code></pre> (Some systems may require you to use <code>pip3</code>, <code>python -m pip</code>, or <code>py -m pip</code> instead)</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome!</p> <p>Please open an issue before submitting a pull request (unless it's a minor change like fixing a typo).</p> <p>To get started:</p> <ol> <li>Clone your fork of the project.</li> <li>Set up the project with <code>just install</code> (uses uv).</li> <li>After you're done, run <code>just check</code> to check your changes.</li> </ol> <p>Note</p> <p>If you don't want to use <code>just</code>, simply look up the recipes in the project's <code>justfile</code>.</p>"},{"location":"#license","title":"License","text":"<p>Crossandra is licensed under the MIT License.</p> <p>If you have any questions, or would like to get in touch, join my Discord server!</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#brainfuck","title":"Brainfuck","text":"<pre><code>from enum import Enum\nfrom crossandra import Crossandra\n\nclass Brainfuck(Enum):\n    ADD = \"+\"\n    SUB = \"-\"\n    LEFT = \"&lt;\"\n    RIGHT = \"&gt;\"\n    READ = \",\"\n    WRITE = \".\"\n    BEGIN_LOOP = \"[\"\n    END_LOOP = \"]\"\n\nbf = Crossandra(Brainfuck, suppress_unknown=True)\nprint(*bf.tokenize(\"cat program: ,[.,]\"), sep=\"\\n\")\n# Brainfuck.READ\n# Brainfuck.BEGIN_LOOP\n# Brainfuck.WRITE\n# Brainfuck.READ\n# Brainfuck.END_LOOP\n</code></pre>"},{"location":"examples/#word-tokenization-with-hex2rgb-conversion","title":"Word tokenization with HEX2RGB conversion","text":"<pre><code>from crossandra import Crossandra, Rule, common\n\ndef hex2rgb(hex_color: str) -&gt; tuple[int, int, int]:\n    r, g, b = (int(hex_color[i:i+2], 16) for i in range(1, 6, 2))\n    return r, g, b\n\nt = Crossandra(\n    ignore_whitespace=True,\n    rules=[\n        Rule(r\"#[0-9a-fA-F]{6}\", hex2rgb),\n        common.WORD\n    ]\n)\n\ntext = \"My favorite color is #facade\"\nprint(t.tokenize(text))\n# ['My', 'favorite', 'color', 'is', (250, 202, 222)]\n</code></pre>"},{"location":"examples/#supporting-samariums-numbers-and-arithmetic-operators","title":"Supporting Samarium's numbers and arithmetic operators","text":"<pre><code>from enum import Enum\nfrom crossandra import Crossandra, Rule\n\ndef sm_int(string: str) -&gt; int:\n    return int(string.replace(\"/\", \"1\").replace(\"\\\\\", \"0\"), 2)\n\nclass Op(Enum):\n    ADD = \"+\"\n    SUB = \"-\"\n    MUL = \"++\"\n    DIV = \"--\"\n    POW = \"+++\"\n    MOD = \"---\"\n\nsm = Crossandra(\n    Op,\n    ignore_whitespace=True,\n    rules=[Rule(r\"[\\\\/]+\", sm_int)]\n)\n\nprint(*sm.tokenize(r\"//\\ ++ /\\\\/ --- /\\/\\/ - ///\"))\n# 6 Op.MUL 9 Op.MOD 21 Op.SUB 7\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#crossandra","title":"<code>Crossandra</code>","text":"<p><pre><code>class Crossandra(\n    token_source: type[Enum] = Empty,\n    *,\n    convert_crlf: bool = True,\n    ignore_whitespace: bool = False,\n    ignored_characters: str = \"\",\n    rules: list[Rule[Any] | RuleGroup] | None = None,\n    suppress_unknown: bool = False,\n)\n</code></pre> The core class representing a <code>Crossandra</code> tokenizer. Takes the following arguments:</p> <ul> <li><code>token_source</code>: an enum containing all possible tokens (defaults to an empty   enum)</li> <li><code>convert_crlf</code>: whether <code>\\r\\n</code> should be converted to <code>\\n</code> before tokenization</li> <li><code>ignored_characters</code>: a string of characters to ignore (defaults to <code>\"\"</code>)</li> <li><code>ignore_whitespace</code>: whether spaces, tabs, newlines etc. should be ignored   (defaults to <code>False</code>)</li> <li><code>suppress_unknown</code>: whether unknown-token errors should be suppressed   (defaults to <code>False</code>)</li> <li><code>rules</code>: a list of additional rules to use</li> </ul> <p>The enum takes priority over the rule list. The rules are prioritized in the order they appear in the list (descending).</p> <p>Token enums can allow a tuple of values as aliases: <pre><code>class MarkdownStyle(Enum):\n    BOLD = \"**\"\n    ITALIC = (\"_\", \"*\")\n    UNDERLINE = \"__\"\n    STRIKETHROUGH = \"~~\"\n    CODE = (\"`\", \"``\")\n\n\nprint(\n    *Crossandra(MarkdownStyle, ignore_whitespace=True).tokenize(\"* ** _ __\"),\n    sep=\"\\n\"\n)\n# &lt;MarkdownStyle.ITALIC: ('*', '_')&gt;\n# &lt;MarkdownStyle.BOLD: '**'&gt;\n# &lt;MarkdownStyle.ITALIC: ('*', '_')&gt;\n# &lt;MarkdownStyle.UNDERLINE: '__'&gt;\n</code></pre></p>"},{"location":"reference/#crossandratokenize","title":"<code>Crossandra.tokenize</code>","text":"<p><pre><code>def tokenize(self, code: str) -&gt; list[Enum | Any]\n</code></pre> Tokenizes the input string. Returns a list of tokens.</p>"},{"location":"reference/#crossandratokenize_lines","title":"<code>Crossandra.tokenize_lines</code>","text":"<p><pre><code>def tokenize_lines(self, code: str) -&gt; list[list[Enum | Any]]\n</code></pre> Tokenizes the input string line by line. Returns a nested list of tokens, where each inner list corresponds to a consecutive line of the input string. Equivalent to <code>[foo.tokenize(line) for line in source.splitlines()]</code>.</p>"},{"location":"reference/#fast-mode","title":"Fast Mode","text":"<p>When all tokens are of length 1 and there are no additional rules, Crossandra will use a simpler tokenization method (the so called Fast Mode).</p> <p>Example</p> <p>Tokenizing noisy Brainfuck code (<code>BrainfuckToken</code> taken from examples)</p> <p>(tested on MacBook Air M1 (256/16) with pure Python wheels) <pre><code># Setup\nfrom random import choices\nfrom string import punctuation\n\nprogram = \"\".join(choices(punctuation, k=...))\ntokenizer = Crossandra(Brainfuck, suppress_unknown=True)\n</code></pre></p> log10(k) Default Fast Mode Speedup 1 40\u00b5s 20\u00b5s 100% 2 160\u00b5s 30\u00b5s 433% 3 1.5ms 130\u00b5s 1,054% 4 14ms 900\u00b5s 1,456% 5 290ms 9ms 3,122%"},{"location":"reference/#rules-and-rule-groups","title":"Rules and rule groups","text":""},{"location":"reference/#rule","title":"<code>Rule</code>","text":"<p><pre><code>class Rule[T](\n    pattern: Pattern[str] | str,\n    converter: Callable[[str], T] | None = None,\n    *,\n    flags: RegexFlag | int = 0,\n    ignore: bool = False,\n)\n</code></pre> Used for defining custom rules. <code>pattern</code> is a regex pattern to match (<code>flags</code> can be supplied). A <code>converter</code> can be supplied and will be called with the matched substring as the argument (defaults to <code>None</code>, returning the matched string directly). When <code>ignore</code> is <code>True</code>, the matched substring will be excluded from the output.</p> <p><code>Rule</code> objects are hashable and comparable and can be ORed (<code>|</code>) for grouping with other <code>Rule</code>s and <code>RuleGroup</code>s.</p>"},{"location":"reference/#ruleapply","title":"<code>Rule.apply</code>","text":"<p><pre><code>def apply(self, target: str) -&gt; tuple[T | str | Ignored, int] | NotApplied\n</code></pre> Checks if <code>target</code> matches the Rule's pattern. If it does, returns a tuple with</p> <ul> <li>if <code>ignore=True</code>: the <code>Ignored</code> sentinel</li> <li>if <code>converter=None</code>: the matched substring</li> <li>otherwise: the result of calling the Rule's converter on the matched substring</li> </ul> <p>and the length of the matched substring. If it doesn't, returns the <code>NotApplied</code> sentinel.</p>"},{"location":"reference/#rulegroup","title":"<code>RuleGroup</code>","text":"<p><pre><code>class RuleGroup(rules: tuple[Rule[Any], ...])\n</code></pre> Used for storing multiple Rules in one object. <code>RuleGroup</code>s can be constructed by passing in a tuple of rules or by ORing (<code>|</code>) two or more <code>Rule</code>s, and they can be ORed with other <code>RuleGroup</code>s or <code>Rule</code>s themselves. <code>RuleGroup</code>s are hashable and iterable.</p>"},{"location":"reference/#rulegroupapply","title":"<code>RuleGroup.apply</code>","text":"<p><pre><code>def apply(self, target: str) -&gt; tuple[Any | str | Ignored, int] | NotApplied\n</code></pre> Applies the rules in the group to the target string. Returns the result of the first rule that matches, or <code>NotApplied</code> if none do.</p>"},{"location":"reference/#common-patterns","title":"Common patterns","text":"<p>The <code>common</code> submodule is a collection of commonly used patterns.</p>"},{"location":"reference/#rules","title":"Rules","text":"<ul> <li>CHAR (e.g. <code>'h'</code>)</li> <li>LETTER (e.g. <code>m</code>)</li> <li>WORD (e.g. <code>ball</code>)</li> <li>SINGLE_QUOTED_STRING (e.g. <code>'nice fish'</code>)</li> <li>DOUBLE_QUOTED_STRING (e.g. <code>\"hello there\"</code>)</li> <li>C_NAME (e.g. <code>crossandra_rocks</code>)</li> <li>NEWLINE (<code>\\r\\n</code> or <code>\\n</code>)</li> <li>DIGIT (e.g. <code>7</code>)</li> <li>HEXDIGIT (e.g. <code>c</code>)</li> <li>DECIMAL (e.g. <code>3.14</code>)</li> <li>INT (e.g. <code>2137</code>)</li> <li>SIGNED_INT (e.g. <code>-1</code>)</li> <li>FLOAT (e.g. <code>1e3</code>)</li> <li>SIGNED_FLOAT (e.g. <code>+4.3</code>)</li> </ul>"},{"location":"reference/#rule-groups","title":"Rule groups","text":"<ul> <li>STRING (<code>SINGLE_QUOTED_STRING | DOUBLE_QUOTED_STRING</code>)</li> <li>NUMBER (<code>INT | FLOAT</code>)</li> <li>SIGNED_NUMBER (<code>SIGNED_INT | SIGNED_FLOAT</code>)</li> <li>ANY_INT (<code>INT | SIGNED_INT</code>)</li> <li>ANY_FLOAT (<code>FLOAT | SIGNED_FLOAT</code>)</li> <li>ANY_NUMBER (<code>NUMBER | SIGNED_NUMBER</code>)</li> </ul>"}]}